{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e69c11-6b1e-4db5-a227-67d84495cc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import deepxde as dde\n",
    "import numpy as np\n",
    "from typing import cast, Any\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450837f4-fa8e-404b-9f35-38558d89bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaminarFlow2D:\n",
    "    \"\"\"Class modeling the laminar flow in 2+1 dimensions.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        rho (float): Fluid density.\n",
    "        u_inf (float): Velocity of the fluid at the inlet.\n",
    "        reynolds (float): Reynolds number.\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = (\"rho\", \"u_inf\", \"reynolds\", \"nu\")\n",
    "\n",
    "    def __init__(self, rho: float, u_inf: float, reynolds: float):\n",
    "        # PDE parameters\n",
    "        self.rho = rho\n",
    "        self.u_inf = u_inf\n",
    "        self.reynolds = reynolds\n",
    "        self.nu = self.u_inf / self.reynolds\n",
    "\n",
    "    def equation(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Defines the ODE.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input of the neural network.\n",
    "            y (torch.Tensor): Output of the neural network.\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Residual of the differential equation.\n",
    "\n",
    "        \"\"\"\n",
    "        ux, uy, p = y[:, 0:1], y[:, 1:2], y[:, 2:]\n",
    "\n",
    "        ux_x = cast(torch.Tensor, dde.grad.jacobian(y, x, i=0, j=0))\n",
    "        ux_y = cast(torch.Tensor, dde.grad.jacobian(y, x, i=0, j=1))\n",
    "        ux_t = cast(torch.Tensor, dde.grad.jacobian(y, x, i=0, j=2))\n",
    "        uy_x = cast(torch.Tensor, dde.grad.jacobian(y, x, i=1, j=0))\n",
    "        uy_y = cast(torch.Tensor, dde.grad.jacobian(y, x, i=1, j=1))\n",
    "        uy_t = cast(torch.Tensor, dde.grad.jacobian(y, x, i=1, j=2))\n",
    "        p_x = cast(torch.Tensor, dde.grad.jacobian(y, x, i=2, j=0))\n",
    "        p_y = cast(torch.Tensor, dde.grad.jacobian(y, x, i=2, j=1))\n",
    "\n",
    "        ux_xx = cast(torch.Tensor, dde.grad.hessian(y, x, i=0, j=0, component=0))\n",
    "        ux_xy = cast(torch.Tensor, dde.grad.hessian(y, x, i=0, j=1, component=0))\n",
    "        ux_yy = cast(torch.Tensor, dde.grad.hessian(y, x, i=1, j=1, component=0))\n",
    "        uy_xx = cast(torch.Tensor, dde.grad.hessian(y, x, i=0, j=0, component=1))\n",
    "        uy_xy = cast(torch.Tensor, dde.grad.hessian(y, x, i=0, j=1, component=1))\n",
    "        uy_yy = cast(torch.Tensor, dde.grad.hessian(y, x, i=1, j=1, component=1))\n",
    "\n",
    "        pde = [\n",
    "            ux_t + ux * ux_x + uy * ux_y + p_x / self.rho - self.nu * (ux_xx + ux_yy),\n",
    "            uy_t + ux * uy_x + uy * uy_y + p_y / self.rho - self.nu * (uy_xx + uy_yy),\n",
    "            ux_x + uy_y,\n",
    "        ]\n",
    "\n",
    "        return pde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9591b8a7-6ab8-4735-bf71-41c1312f6bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equation parameters\n",
    "\n",
    "rho = 1\n",
    "u_inf = 1\n",
    "reynolds = 0.1\n",
    "radius = 0.1\n",
    "\n",
    "# Neural network parameters\n",
    "input_size = [3]\n",
    "output_size = [3]\n",
    "layers_sizes = input_size + [16, 32, 16] + output_size\n",
    "activation = \"tanh\"\n",
    "initializer = \"Glorot normal\"\n",
    "\n",
    "# Training parameters\n",
    "optimizer_kw = dict(\n",
    "    lr=0.001,\n",
    "    metrics=[\"l2 relative error\"],\n",
    "    # loss_weights=[0.001, 1, 1],\n",
    ")\n",
    "n_iterations = 10_000\n",
    "\n",
    "# Mesh parameters\n",
    "n_training_inside = 5000\n",
    "n_training_bdy = 500\n",
    "n_training_initial = 500\n",
    "# n_test = 5000\n",
    "\n",
    "# Ranges\n",
    "x_begin = 0\n",
    "x_end = 2\n",
    "y_begin = 0\n",
    "y_end = 1\n",
    "t_begin = 0\n",
    "t_end = 1\n",
    "\n",
    "\n",
    "def solve_problem(\n",
    "    reynolds: float,\n",
    ") -> tuple[LaminarFlow2D, dde.Model, dde.model.LossHistory, dde.model.TrainState]:\n",
    "    \"\"\"Given the parameters, defines the model and trains the model.\"\"\"\n",
    "    # System\n",
    "    laminar_eq = LaminarFlow2D(rho=rho, u_inf=u_inf, reynolds=reynolds)\n",
    "\n",
    "    # Geometry description\n",
    "    outer = dde.geometry.Rectangle(xmin=[x_begin, y_begin], xmax=[x_end, y_end])\n",
    "    inner = dde.geometry.Disk([0.5, 0.5], radius)\n",
    "    geom_space = outer\n",
    "    # geom_space = outer - inner\n",
    "    geom_time = dde.geometry.TimeDomain(t_begin, t_end)\n",
    "    geom_full = dde.geometry.GeometryXTime(geom_space, geom_time)\n",
    "\n",
    "    def boundary_edges(x, on_boundary):\n",
    "        return on_boundary and (\n",
    "            dde.utils.isclose(x[1], y_end) or dde.utils.isclose(x[1], y_begin)\n",
    "        )\n",
    "\n",
    "    def boundary_outflow(x, on_boundary):\n",
    "        return on_boundary and dde.utils.isclose(x[0], x_end)\n",
    "\n",
    "    def boundary_inflow(x, on_boundary):\n",
    "        return on_boundary and dde.utils.isclose(x[0], x_begin)\n",
    "\n",
    "    def boundary_inner(x, on_boundary):\n",
    "        return on_boundary and inner.on_boundary(x)\n",
    "\n",
    "    # BCs\n",
    "    # No slip on the sphere\n",
    "    bc_noslip = [\n",
    "        dde.icbc.DirichletBC(geom_full, lambda x: 0, boundary_inner, component=0),\n",
    "        dde.icbc.DirichletBC(geom_full, lambda x: 0, boundary_inner, component=1),\n",
    "    ]\n",
    "    # Inlet\n",
    "    bc_in = [\n",
    "        dde.icbc.DirichletBC(geom_full, lambda x: u_inf, boundary_inflow, component=0),\n",
    "        dde.icbc.DirichletBC(geom_full, lambda x: 0, boundary_inflow, component=1),\n",
    "        dde.icbc.OperatorBC(\n",
    "            geom_full,\n",
    "            lambda x, y, _: dde.grad.jacobian(y, x, i=2, j=0),\n",
    "            boundary_outflow,\n",
    "            # component=2,\n",
    "        ),\n",
    "    ]\n",
    "    # Outlet\n",
    "    bc_out = [\n",
    "        dde.icbc.OperatorBC(\n",
    "            geom_full,\n",
    "            lambda x, y, _: dde.grad.jacobian(y, x, i=0, j=0),\n",
    "            boundary_outflow,\n",
    "            # component=0,\n",
    "        ),\n",
    "        dde.icbc.OperatorBC(\n",
    "            geom_full,\n",
    "            lambda x, y, _: dde.grad.jacobian(y, x, i=1, j=0),\n",
    "            boundary_outflow,\n",
    "            # component=1,\n",
    "        ),\n",
    "        dde.icbc.DirichletBC(geom_full, lambda x: 0, boundary_outflow, component=2),\n",
    "    ]\n",
    "    # Edges\n",
    "    bc_edges = [\n",
    "        dde.icbc.DirichletBC(geom_full, lambda x: u_inf, boundary_edges, component=0),\n",
    "        dde.icbc.DirichletBC(geom_full, lambda x: 0, boundary_edges, component=1),\n",
    "        dde.icbc.OperatorBC(\n",
    "            geom_full,\n",
    "            lambda x, y, _: dde.grad.jacobian(y, x, i=2, j=1),\n",
    "            boundary_edges,\n",
    "            # component=2,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Initial value\n",
    "    ic = [\n",
    "        dde.icbc.IC(\n",
    "            geom_full, lambda x: u_inf, lambda _, on_initial: on_initial, component=0\n",
    "        ),\n",
    "        dde.icbc.IC(\n",
    "            geom_full, lambda x: 0, lambda _, on_initial: on_initial, component=1\n",
    "        ),\n",
    "        dde.icbc.IC(\n",
    "            geom_full, lambda x: 0, lambda _, on_initial: on_initial, component=2\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Load data\n",
    "    data = dde.data.TimePDE(\n",
    "        geom_full,\n",
    "        laminar_eq.equation,\n",
    "        [\n",
    "            # *bc_noslip,\n",
    "            *bc_in,\n",
    "            *bc_out,\n",
    "            *bc_edges,\n",
    "            *ic,\n",
    "        ],\n",
    "        num_domain=n_training_inside,\n",
    "        num_boundary=n_training_bdy,\n",
    "        num_initial=n_training_initial,\n",
    "        solution=lambda x: [1, 1, 1],\n",
    "        num_test=10,\n",
    "    )\n",
    "\n",
    "    neural_net = dde.nn.FNN(layers_sizes, activation, initializer)\n",
    "    # neural_net.apply_output_transform(lambda x, y: abs(y))\n",
    "    model = dde.Model(data, neural_net)\n",
    "    model.compile(\"adam\", **optimizer_kw)\n",
    "    # model.train(iterations=n_iterations)\n",
    "    # model.compile(\"L-BFGS\")\n",
    "    losshistory, train_state = model.train(iterations=n_iterations)\n",
    "\n",
    "    return laminar_eq, model, losshistory, train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c145ae9-10e3-430a-812e-ea51e436da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(\n",
    "    laminar_eq: LaminarFlow2D, model: dde.Model, n_dim: int, n_time: int\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    x = np.linspace(x_begin, x_end, n_dim)\n",
    "    y = np.linspace(y_begin, y_end, n_dim)\n",
    "    t = np.linspace(t_begin, t_end, n_time)\n",
    "    X, Y, T = np.meshgrid(x, y, t)\n",
    "    grid = np.stack([X.flatten(), Y.flatten(), T.flatten()], axis=1)\n",
    "\n",
    "    y_predict = model.predict(grid)\n",
    "    y_predict = y_predict.reshape((n_dim, n_dim, n_time))\n",
    "    return (x, y, t), y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fbeed4cc-7ad8-4913-9969-dc39ef227a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true: np.ndarray, y_predict: np.ndarray) -> float:\n",
    "    return np.mean(np.abs(y_true - y_predict))\n",
    "\n",
    "\n",
    "def plot_result(\n",
    "    coords: np.ndarray, y_predict: np.ndarray, y_true: np.ndarray, n: int, kappa: float\n",
    ") -> go.Figure:\n",
    "    width = 600\n",
    "    height = 600\n",
    "    scale = 3\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=go.Heatmap(\n",
    "            z=y_predict.T,\n",
    "            x=coords[1],\n",
    "            y=coords[0],\n",
    "            colorscale=\"RdBu_r\",\n",
    "            zmin=-1,\n",
    "            zmax=1,\n",
    "            colorbar=dict(\n",
    "                title=dict(text=\"Temperature difference\", side=\"bottom\"),\n",
    "                orientation=\"h\",\n",
    "                x=0.5,\n",
    "                y=-0.2,\n",
    "                xanchor=\"center\",\n",
    "                yanchor=\"top\",\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    error = mae(y_true.flatten(), y_predict.flatten())\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        title=dict(\n",
    "            text=f\"Case n={n}, diffusivity = {kappa:.1E}, MAE: {error:.2E}\",\n",
    "            y=0.91,\n",
    "            x=0.5,\n",
    "            xanchor=\"center\",\n",
    "            yanchor=\"bottom\",\n",
    "        ),\n",
    "        xaxis=dict(title=dict(text=\"t\")),\n",
    "        yaxis=dict(title=dict(text=\"x\")),\n",
    "        font=dict(size=14),\n",
    "        margin=dict(l=40, r=40, t=60, b=60),\n",
    "    )\n",
    "    fig.write_image(\n",
    "        f\"../figs/heat_equation_n={n}.png\",\n",
    "        width=width,\n",
    "        height=height,\n",
    "        scale=scale,\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10c7d116-7cc9-48b3-a54c-ee5e9afe8f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 5 points required, but 8 points sampled.\n",
      "Warning: 10 points required, but 16 points sampled.\n",
      "Compiling model...\n",
      "'compile' took 0.000096 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "0         [4.39e+00, 1.01e+00, 2.97e-01, 1.14e+00, 9.21e-03, 1.93e-02, 5.11e-02, 3.93e-03, 2.29e-01, 2.23e+00, 4.99e-02, 9.52e-04, 2.24e+00, 7.74e-02, 9.93e-02][4.57e+00, 6.09e-01, 3.19e-01, 1.14e+00, 9.21e-03, 1.93e-02, 5.11e-02, 3.93e-03, 2.29e-01, 2.23e+00, 4.99e-02, 9.52e-04, 2.24e+00, 7.74e-02, 9.93e-02][1.84e+00, 1.78e+00, 1.79e+00]    \n",
      "1000      [1.16e-03, 4.53e-04, 4.38e-05, 3.57e-05, 1.47e-05, 7.17e-05, 1.50e-04, 2.94e-05, 2.46e-05, 7.48e-05, 2.59e-05, 1.22e-04, 3.68e-05, 4.93e-06, 1.59e-04][1.58e-03, 1.84e-04, 5.55e-05, 3.57e-05, 1.47e-05, 7.17e-05, 1.50e-04, 2.94e-05, 2.46e-05, 7.48e-05, 2.59e-05, 1.22e-04, 3.68e-05, 4.93e-06, 1.59e-04][1.42e+00, 1.40e+00, 1.42e+00]    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Training parameters\u001b[39;00m\n\u001b[1;32m      3\u001b[0m optimizer_kw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m      4\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m      5\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2 relative error\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# loss_weights=[0.001, 2, 0.5],\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m heat_eq, model, loss_history, train_state \u001b[38;5;241m=\u001b[39m \u001b[43msolve_problem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreynolds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreynolds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m dde\u001b[38;5;241m.\u001b[39msaveplot(loss_history, train_state, issave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, isplot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# plot_result(train_state, name_case=\"underdamped\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[90], line 149\u001b[0m, in \u001b[0;36msolve_problem\u001b[0;34m(reynolds)\u001b[0m\n\u001b[1;32m    146\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptimizer_kw)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# model.train(iterations=n_iterations)\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# model.compile(\"L-BFGS\")\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m losshistory, train_state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m laminar_eq, model, losshistory, train_state\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/deepxde/utils/internal.py:22\u001b[0m, in \u001b[0;36mtiming.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     21\u001b[0m     ts \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[0;32m---> 22\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     te \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m     24\u001b[0m     verbose \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/deepxde/model.py:690\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, iterations, batch_size, display_every, disregard_previous_best, callbacks, model_restore_path, model_save_path, epochs, verbose)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iterations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo iterations for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_name))\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_sgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_train_end()\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/deepxde/model.py:708\u001b[0m, in \u001b[0;36mModel._train_sgd\u001b[0;34m(self, iterations, display_every, verbose)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_batch_begin()\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mset_data_train(\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_next_batch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    707\u001b[0m )\n\u001b[0;32m--> 708\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_aux_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/deepxde/model.py:595\u001b[0m, in \u001b[0;36mModel._train_step\u001b[0;34m(self, inputs, targets, auxiliary_vars)\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(inputs, targets, auxiliary_vars)\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 595\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauxiliary_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;66;03m# TODO: auxiliary_vars\u001b[39;00m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_state, inputs, targets\n\u001b[1;32m    600\u001b[0m     )\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/deepxde/model.py:377\u001b[0m, in \u001b[0;36mModel._compile_pytorch.<locals>.train_step\u001b[0;34m(inputs, targets, auxiliary_vars)\u001b[0m\n\u001b[1;32m    374\u001b[0m     total_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss\n\u001b[0;32m--> 377\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 223\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    226\u001b[0m     params_with_grad: List[Tensor] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/deepxde/model.py:374\u001b[0m, in \u001b[0;36mModel._compile_pytorch.<locals>.train_step.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    372\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(losses)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 374\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/torch/_tensor.py:617\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03m        used to compute the :attr:`tensors`.\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    628\u001b[0m )\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/torch/overrides.py:1720\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1718\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1720\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1722\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/torch/utils/_device.py:104\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devs/projects/pinn/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reynolds = 0.1\n",
    "# Training parameters\n",
    "optimizer_kw = dict(\n",
    "    lr=0.001,\n",
    "    metrics=[\"l2 relative error\"],\n",
    "    # loss_weights=[0.001, 2, 0.5],\n",
    ")\n",
    "heat_eq, model, loss_history, train_state = solve_problem(reynolds=reynolds)\n",
    "dde.saveplot(loss_history, train_state, issave=False, isplot=True)\n",
    "# plot_result(train_state, name_case=\"underdamped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71aa74c-062e-4922-a4f9-425d3afde729",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, y_predict, y_true = get_predictions(heat_eq, model, 1000)\n",
    "plot_result(coords, y_predict, y_true, n=1, kappa=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde4efcd-35f0-4588-b675-4c9f0a04869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "kappa = 0.025\n",
    "# Training parameters\n",
    "optimizer_kw = dict(\n",
    "    lr=0.001,\n",
    "    metrics=[\"l2 relative error\"],\n",
    "    # loss_weights=[0.001, 2, 0.5],\n",
    ")\n",
    "heat_eq_2, model_2, loss_history_2, train_state_2 = solve_problem(kappa=kappa, n=n, kappa=kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ffd784-67e2-4e94-bdee-c59b4278bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dde.saveplot(loss_history_2, train_state_2, issave=False, isplot=True)\n",
    "# plot_result(train_state, name_case=\"underdamped\")\n",
    "\n",
    "coords, y_predict, y_true = get_predictions(heat_eq_2, model_2, 1000)\n",
    "plot_result(coords, y_predict, y_true, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00db8cf-326e-464a-9056-312413c2fa9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinns",
   "language": "python",
   "name": "pinns"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
